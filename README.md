# tieba_spider

百度贴吧爬虫——获取页面信息<br>
A way to get specific module of Baidu Tieba.<br>

## Getting Started

1. 运行spider_tieba_gener.py获取网页数据，需要修改文件，详情可查看注释<br>
2. 将所有评论信息保存至一个文本文件，运行wordcut.py<br>
3. 词云绘制，运行wordclouddraw.py<br>

## Prerequisites

Python 3.X

> jieba<br>
> bs4<br>
> wordcloud<br>
> pandas<br>
> opencv-python<br>
> some build-in modules like time, csv, json<br>


## Additional Documentation and Acknowledgments
1. [中文停用词表](https://github.com/goto456/stopwords)<br>
2. [字体](https://www.100font.com/thread-562.htm)<br>
